{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os.path\n",
    "# import os\n",
    "import dalmatian as dm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0, '../../JKBio/')\n",
    "import TerraFunction as terra\n",
    "import CCLF_processing\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext rpy2.ipython\n",
    "from IPython.display import Image, display, HTML\n",
    "import ipdb\n",
    "\n",
    "# Import requirements for making CNV plots\n",
    "from matplotlib import pyplot as plt\n",
    "import cnvlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qgrid # interactive tables\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "import gcsfs # to be able to read in files from GCS in Python\n",
    "import re # used for regex\n",
    "\n",
    "# Extra options\n",
    "qgrid.set_grid_option('maxVisibleRows', 10)\n",
    "\n",
    "# # Show all code cells outputs\n",
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "# InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "participant = \"PEDS204\"\n",
    "\n",
    "# path would be the participant-specific path\n",
    "# path = \"gs://cclf_results/targeted/neekesh_201912/\" \n",
    "path = \"gs://cclf_results/targeted/neekesh_201912/Wilms_Tumor/PEDS204/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretty report generation\n",
    "After grabbing and making all of the files we want for a given participant (e.g. PEDS182), we want to make a pretty, interactive report. This will be similar to a README except that we will directly embed tables and images. This involves using Jupyter widgets to create dropdown menus and the like. Here are the main functionalities I'd like:\n",
    "\n",
    "1. kable-like tables that are interactive: sorting, filtering, typing in text or numbers to search, (ability to download sorted/filtered table as a CSV?)\n",
    "2. ability to quickly go to any image in the directory. I want this so that the user can quickly look through the copy number maps (horizontal plots). Ideally, I'd like to be able to select which one(s) I'd like to view. This could be useful if they want to see two or more at once (i.e. to compare two treatment conditions).\n",
    "\n",
    "## Automate generation of separate Jupyter notebook for each participant\n",
    "To do this, we will use Papermill. Papermill automates notebook to notebook generation, and also executes the generated notebook. We may also want to convert the generated notebook to HTML. We can use *nbconvert* for this operation (see https://github.com/jupyter/nbconvert)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_tables(filepaths):\n",
    "    \"\"\" takes list of filepaths to TSVs and returns dataframes read in by Pandas\"\"\"\n",
    "    return [pd.read_csv(f, sep='\\t', index_col = None) for f in filepaths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of file paths for the selected participant\n",
    "filepaths = ! gsutil ls -r {path}**\n",
    "\n",
    "# Get all the table filepaths in the bucket\n",
    "table_filepaths = ! gsutil ls -r {path}*.txt # check: will this search recursively for all .txt files?\n",
    "to_add = ! gsutil ls -r {path}**.tsv\n",
    "table_filepaths += to_add\n",
    "\n",
    "# Get all the png filepaths in the bucket\n",
    "img_filepaths = ! gsutil ls -r {path}**.png\n",
    "\n",
    "# Copy all the pngs in the bucket to a tmp folder\n",
    "# TODO: need to delete the files afterwards\n",
    "tempdir='../temp/cclfreport/images/'\n",
    "! gsutil cp -r {path}**.png {tempdir} # copy images from google bucket to local temp folder\n",
    "# local_img_filepaths = ! ls {tempdir}*.png\n",
    "local_img_filepaths = [tempdir + os.path.basename(i) for i in img_filepaths]\n",
    "print(local_img_filepaths)\n",
    "\n",
    "os.chdir(tempdir)\n",
    "local_img_file_names = [os.path.basename(i) for i in local_img_filepaths]\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_interactive_table(filepath, cols_to_include = None):\n",
    "    \"\"\"Takes single pd dataframe as input\"\"\"\n",
    "    if type(filepath) != pd.core.frame.DataFrame:\n",
    "        raise Exception(\"The function expected a pandas dataframe as input, but got: \", str(type(filepath)))\n",
    "    data = filepath\n",
    "    \n",
    "    # Subset the data to include the specified columns, if any passed in\n",
    "    if cols_to_include is not None:\n",
    "        # The index is the first column listed\n",
    "        index_name = cols_to_include[0]\n",
    "        data = data[cols_to_include]\n",
    "        data.set_index(index_name, inplace=True, drop=True)\n",
    "        if 'keep' in cols_to_include:\n",
    "            data = data.loc[data['keep'] == True]\n",
    "            \n",
    "    # Create and display interactive table\n",
    "    qgrid_widget = qgrid.show_grid(data, show_toolbar=False, grid_options = {'forceFitColumns': False,\n",
    "    'defaultColumnWidth': 150})\n",
    "    display(qgrid_widget)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample information and identifiers\n",
    "This section details the external IDs for all the samples we discovered when searching the existing targeted probe data and WES data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_external_ids = ! gsutil ls -r {path}**all_external_ids.tsv\n",
    "all_failed_external_ids = ! gsutil ls -r {path}**all_failed_external_ids.tsv\n",
    "\n",
    "# Read in the tables\n",
    "all_external_ids_df = read_in_tables(all_external_ids)\n",
    "all_failed_external_ids_df = read_in_tables(all_failed_external_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table: all external IDs & associated metadata\n",
    "The below table is sortable and filterable. You can double-click on the cells in the table if you want to copy the contents, like if you wanted to copy the link to the file in the Google storage console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a table with metadata for each external ID\n",
    "\n",
    "df1 = all_external_ids_df[0]\n",
    "df1['participant'] = str(os.path.basename(os.path.dirname(all_external_ids[0])))\n",
    "df1['disease'] = str(os.path.basename(os.path.dirname(os.path.dirname(all_external_ids[0]))))\n",
    "df1['filepath'] = str(os.path.dirname(all_external_ids[0]))\n",
    "df1['link'] = str(re.sub('gs://', 'https://console.cloud.google.com/storage/browser/', os.path.dirname(all_external_ids[0])))\n",
    "\n",
    "df1.set_index('participant', drop=True, inplace=True)\n",
    "\n",
    "# Print some summary information\n",
    "print(\"We found a total of\", df1.shape[0],\"external IDs that passed the depth of coverage QC.\")\n",
    "print(\"Do note that some of these samples may not have been processed yet.\")\n",
    "# TODO: add metadata showing whether we have processed CN, SNV, etc. Ask what other metadata would be useful.\n",
    "\n",
    "# Display an interactive table\n",
    "qgrid_widget = qgrid.show_grid(df1, show_toolbar=False, grid_options = {'forceFitColumns': False})\n",
    "display(qgrid_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samples that failed the depth of coverage QC\n",
    "This summary details all the the external IDs of each sample that failed the depth of coverage QC in the targeted probe pipeline. The depth of coverage QC in the targeted probe pipeline requires that the average gene-level or interval-level coverage is >=50x. \n",
    "\n",
    "The summary also lists the participants for which no samples failed the depth of coverage QC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the external IDs that passed the QC\n",
    "failed_qc = False\n",
    "for table,filepath in zip(all_failed_external_ids_df, all_failed_external_ids):\n",
    "    tmp_df = table\n",
    "    participant_name = str(os.path.basename(os.path.dirname(filepath)))\n",
    "    if tmp_df.shape[0] ==1:\n",
    "        print(\"There was\", str(tmp_df.shape[0]), \"failed sample for participant\", participant_name,\":\")\n",
    "        display(sorted(tmp_df.iloc[:,0].tolist()))\n",
    "    elif tmp_df.shape[0] >1:\n",
    "        print(\"There were\", str(tmp_df.shape[0]), \"failed samples for participant\", participant_name)\n",
    "    else:\n",
    "        failed_qc = True\n",
    "\n",
    "# If any samples failed the QC, print them:\n",
    "if failed_qc:\n",
    "    print(\"There were no failed samples for participant\", participant_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy number data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy number heat maps\n",
    "There are two plots in this section, one for CN data from the targeted probe data and a second for CN data from WES data. To look at any one sample in more detail, you can look either at the corresponding horizontal CN plot in the next section titled \"Copy number horizontal plots\" or look at the CN table (see either the tables below or the TSV available at the link specified in the \"Sample information and identifiers\" section.\n",
    "\n",
    "These tables are searchable and filterable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Targeted CN heat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a heat map specific to the samples requested (either per participant basis or per list of participants) using the plotSomaticCNV workflow in Terra\n",
    "# Steps: create a new sample set with the appropriate samples, submit a new job, wait for it to finish, copy the picture to the temp dir (and add it to the list of local files), then display it here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WES CN heat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what's the best way to create a CN heat map for the WES samples? create just using the segmented CN tsv I pull in from Terra? create new workflow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cntempdir = '../temp/cclfreport/tables/'\n",
    "all_cn_tables = wes_cn + tsca_cn\n",
    "all_cn_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create single seg file containing all samples from targeted and WES\n",
    "local_cn_filepaths = [cntempdir + os.path.basename(i) for i in all_cn_tables]\n",
    "\n",
    "# Create dict of dicts: {participant_id: {external_id: seg file}}\n",
    "seg_file_dict = dict()\n",
    "seg_columns = [\"external_id\",\"Chromosome\", \"Start\", \"End\", \"Num_Probes\", \"Segment_Mean\"]\n",
    "\n",
    "# Read in tables and merge together into one giant seg file\n",
    "df = pd.concat((pd.read_csv(f,sep=\"\\t\", index_col = None) for f in all_cn_tables))\n",
    "print(set(df.loc[:,\"external_id\"]))\n",
    "\n",
    "# Convert to properly-formatted seg file and \n",
    "# convert the relative copy ratio to the log2(relative copy ratio)\n",
    "df = df.loc[:,seg_columns]\n",
    "df[\"Segment_Mean\"] = np.log2(df[\"Segment_Mean\"])\n",
    "\n",
    "# Write each external_id level table to a seg file (TSV format)\n",
    "tmp_path = cntempdir + participant + \".tsv\"\n",
    "df.to_csv(tmp_path, sep = \"\\t\", index = False)\n",
    "\n",
    "# Convert to .cns format using CNVkit\n",
    "converted = ! cnvkit.py import-seg {tmp_path} -d {cntempdir}\n",
    "\n",
    "# Extract .cns filenames\n",
    "cns_files = []\n",
    "# TODO: fix pattern so that has backslash before .cns. Otherwise, can end with cns instead of requiring .cns!\n",
    "pattern = re.compile(r'{}.*.cns'.format(cntempdir))\n",
    "print(\"pattern:\",pattern)\n",
    "for file in converted:\n",
    "    print(file)\n",
    "    cns_files += [re.search(pattern,file)[0]]\n",
    "cns_files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cntempdir = '../temp/cclfreport/tables/'\n",
    "# local_cn_filepaths = [cntempdir + os.path.basename(i) for i in wes_cn]\n",
    "\n",
    "# # Create dict of dicts: {participant_id: {external_id: seg file}}\n",
    "# seg_file_dict = dict()\n",
    "# seg_columns = [\"external_id\",\"Chromosome\", \"Start\", \"End\", \"Num_Probes\", \"Segment_Mean\"]\n",
    "# for filepath in wes_cn:\n",
    "#     participant_id = str(os.path.basename(os.path.dirname(filepath)))\n",
    "#     df = pd.read_csv(filepath, sep=\"\\t\", index_col = None)\n",
    "#     df = df.loc[:,seg_columns]\n",
    "#     print(\"before:\", df[:5])\n",
    "    \n",
    "#     # Convert the relative copy ratio to the log2(relative copy ratio)\n",
    "#     df[\"Segment_Mean\"] = np.log2(df[\"Segment_Mean\"])\n",
    "#     print(\"after:\", df[:5])\n",
    "\n",
    "#     # Write each external_id level table to a seg file (TSV format)\n",
    "#     tmp_path = cntempdir + participant_id + \".tsv\"\n",
    "#     df.to_csv(tmp_path, sep = \"\\t\", index = False)\n",
    "    \n",
    "#     # Add key:value pair for the seg files for each participant\n",
    "#     seg_file_dict[participant_id] = tmp_path\n",
    "\n",
    "# seg_file_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cntempdir = '../temp/cclfreport/tables/'\n",
    "# local_cn_filepaths = [cntempdir + os.path.basename(i) for i in wes_cn]\n",
    "\n",
    "# for i,gspath in enumerate(wes_cn):\n",
    "#     # Temporarily download CN seg file locally\n",
    "#     ! gsutil cp {gspath} {cntempdir}\n",
    "    \n",
    "#     # Convert to .cns format\n",
    "#     ! cnvkit.py import-seg {local_cn_filepaths[i]}\n",
    "    \n",
    "# # Remove CN seg files from temporary location\n",
    "# ! rm {local_cn_filepaths}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Show all code cells outputs\n",
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "# InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Create CN chromosome plot PDF for each external ID\n",
    "outfilenames = [cntempdir + os.path.basename(ext_id).split(\".\")[0] + \"-diagram.PDF\" for ext_id in cns_files]\n",
    "for ext_id, segfile in enumerate(segments):    tmp = cnvlib.diagram.create_diagram(cnarr = None, segarr = segfile, threshold = 0 , min_probes =3 , outfname = outfilenames[ext_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CN heat map containing all external IDs for the participant\n",
    "# https://cnvkit.readthedocs.io/en/stable/plots.html\n",
    "\n",
    "# TODO: change size of plot dynamically depending on the number of samples to plot\n",
    "segments = [cnvlib.read(f) for f in cns_files]\n",
    "plt.rcParams[\"font.size\"] = 32\n",
    "plt.rcParams['figure.figsize'] = (32,max(6,len(segments)*3))\n",
    "\n",
    "# plt.figure(figsize=(10,6))\n",
    "ax = cnvlib.do_heatmap(segments, do_desaturate=False)\n",
    "ax.set_title(\"Copy number heatmap for all {} samples\".format(participant_id))\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"test.pdf\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy number horizontal plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the copy number plot you would like to display from the dropdown menu. The dropdown menu includes CN plots from both targeted probe (TSCA and TWIST) and WES data. The source of the data will be displayed on the title of the image. You can also refer to the table of all external IDs that maps each external ID to the source of the data (see \"Sample information and identifiers\").\n",
    "\n",
    "The dropdown menu also includes merged copy number maps for each participant. This PNG file contains all the horizontal CN plots for a given participant in a single place for ease of quick comparison.\n",
    "\n",
    "**check:** can I add a linked reference to this table so that they can quickly jump there? Might be best to just make it it's own section so that it shows up in the TOC.\n",
    "\n",
    "<!-- Note that to get nice dropdown menu names, I'm changing directories for now. There's probably a better way to do this. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(tempdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: this isn't the most helpful format / layout currently. Make it possible to select by WES vs Targeted, and select by participant as well. I don't currently know how to do this.\n",
    "# select image to display from dropdown menu    \n",
    "@interact\n",
    "def show_images(file=local_img_file_names):\n",
    "    print(\"File name:\", file)\n",
    "    display(Image(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# must change back to the main directory\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the CN tables from the Google storage bucket\n",
    "tsca_cn = ! gsutil ls -r {path}copy_number.tsv\n",
    "wes_cn = ! gsutil ls -r {path}**wes_copy_number.tsv\n",
    "\n",
    "# Create dictionary with filepaths as keys and pandas DF as the values\n",
    "tsca_cn_dict = {f:pd.read_csv(f, sep=\"\\t\", index_col = None) for f in tsca_cn}\n",
    "wes_cn_dict = {f:pd.read_csv(f, sep=\"\\t\", index_col = None) for f in wes_cn}\n",
    "\n",
    "# CN columns to display in tables\n",
    "cn_col_names = ['external_id', 'Sample', 'condition','Chromosome', 'Start', 'End','Segment_Mean', 'Segment_Call', 'Num_Probes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Targeted CN table\n",
    "Select from the dropdown menu to get the targeted CN table for each participant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_table(file, file_table_dict, cols_to_use):\n",
    "    # Print key information about the file\n",
    "    print(\"Participant: \", str(os.path.basename(os.path.dirname(file))))\n",
    "    print(\"Filepath: \"+ file)\n",
    "    print(\"Link:\", str(re.sub('gs://', 'https://console.cloud.google.com/storage/browser/', file)))\n",
    "    print(\"\\nTo examine data for a particular external ID, filter the 'external_id' column.\")\n",
    "    \n",
    "    # Get the TSV from the dict and display it\n",
    "    df = file_table_dict[file]\n",
    "    try:\n",
    "        make_interactive_table(df, cols_to_include = cols_to_use)\n",
    "    except:\n",
    "        print(\"\\nAt least one of this participant's mutation file is in a different format from the output of the newest pipeline. This data may be old, and have different column names. No filtering is performed on the displayed table, but you can add additional filters if desired:\")\n",
    "        make_interactive_table(df, cols_to_include = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_table(file = tsca_cn[0],file_table_dict = tsca_cn_dict, cols_to_use = cn_col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WES CN table\n",
    "Select from the dropdown menu to get the WES CN table for each participant, when available. The TSV will contain the data for all the different external IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_table(file = wes_cn[0],file_table_dict = wes_cn_dict, cols_to_use = cn_col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maybe think about including mutations found in targeted that WEREN'T found in WES. Or, alternatively, just plot a venn diagram. I can only do this for samples where we have both WES and Targeted data - this shouldn't be difficult to figure out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are interactive tables containing *select* mutation information from the targeted probe data and the WES data. If there were multiple external IDs in either dataset, they have been combined into one table. The external_id column can be used to filter the data so only the mutations for a single external ID is displayed.\n",
    "\n",
    "Note that this report only includes samples from the targeted data that pass the depth of coverage QC. Samples that did not pass this QC are not included in this report, and their data is not included in the Google bucket. A list of the samples that failed this QC is included earlier in this document (search for \"Table: failed QC external IDs\").\n",
    "\n",
    "Also, note that the below tables have been filtered such that the keep column equals True. What this means is that only the variants that passed the filtering steps in the pipeline are included in the tables below. However, the raw mutation TSVs included in the Google bucket contain all the variants regardless of whether keep is True or False if you are interested in that information. This TSV will also contain columns explaining why a mutation was removed during filtration.\n",
    "\n",
    "Generally speaking, if you are looking for more detailed information about why a mutation you expected to see was filtered out or if you want to get access to all of the columns available in the mutation TSV rather than the ones selected here, you can download the raw mutation TSV from the Google bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mutation TSVs\n",
    "tsca_mut = ! gsutil ls -r {path}mutation.tsv\n",
    "wes_mut = ! gsutil ls -r {path}**wes_mutations.tsv\n",
    "\n",
    "# Create dictionary with filepaths as keys and pandas DF as the values\n",
    "tsca_mut_dict = {f:pd.read_csv(f, sep=\"\\t\", index_col = None) for f in tsca_mut}\n",
    "wes_mut_dict = {f:pd.read_csv(f, sep=\"\\t\", index_col = None) for f in wes_mut}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Targeted mutation table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_table(file = tsca_mut[0],file_table_dict = tsca_mut_dict, cols_to_use = mut_col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WES mutation table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_table(file = wes_mut[0],file_table_dict = wes_mut_dict, cols_to_use = mut_col_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "262px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
